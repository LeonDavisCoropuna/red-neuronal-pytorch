{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe658aa3-b08b-4ef9-90aa-954241476dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost es: 0.6012918963363998, y accuray: 0.869\n",
      "cost es: 0.446413044576275, y accuray: 0.9038\n",
      "cost es: 0.2974765023444454, y accuray: 0.9153\n",
      "cost es: 0.2999230542395316, y accuray: 0.9237\n",
      "cost es: 0.3083297608658433, y accuray: 0.9303\n",
      "cost es: 0.28727411161924077, y accuray: 0.9353\n",
      "cost es: 0.1797867301771783, y accuray: 0.9418\n",
      "cost es: 0.2860645885989556, y accuray: 0.9461\n",
      "cost es: 0.1391533896255067, y accuray: 0.9489\n",
      "cost es: 0.25358686516183415, y accuray: 0.9542\n",
      "cost es: 0.1814232106504618, y accuray: 0.9552\n",
      "cost es: 0.19456866106832935, y accuray: 0.9575\n",
      "cost es: 0.18711101835115412, y accuray: 0.9591\n",
      "cost es: 0.17748024282259647, y accuray: 0.9611\n",
      "cost es: 0.1747255616915876, y accuray: 0.9628\n",
      "cost es: 0.14896010519816466, y accuray: 0.9637\n",
      "cost es: 0.13547701229725284, y accuray: 0.9645\n",
      "cost es: 0.1533915524792758, y accuray: 0.9656\n",
      "cost es: 0.13773688129927852, y accuray: 0.9661\n",
      "cost es: 0.1333691355480657, y accuray: 0.9655\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "from minst_read import MnistDataloader\n",
    "input_path = './'\n",
    "training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
    "test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n",
    "\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_train_num, y_train_num), (x_test_num, y_test_num) = mnist_dataloader.load_data()\n",
    "\n",
    "\n",
    "x_train = x_train_num[:50000].reshape(50000,-1).astype(np.float32)/255\n",
    "y_train = y_train_num[:50000].reshape(50000,1)\n",
    "\n",
    "x_val = x_train_num[50000:].reshape(10000,-1).astype(np.float32)/255\n",
    "y_val = y_train_num[50000:].reshape(10000,1)\n",
    "\n",
    "x_test = x_test_num.copy().reshape(10000,-1).astype(np.float32)/255\n",
    "y_test = y_test_num.copy().reshape(10000,1)\n",
    "\n",
    "def plot_number(image):\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def create_minibaches(mb_size, x, y, shuffle = True):\n",
    "    assert x.shape[0] == y.shape[0], 'Diferente tamaÃ±o'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle:\n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))\n",
    "\n",
    "def init_parameters(input_size, neurons):\n",
    "    '''\n",
    "    input_size -> elementos de entrrada , 784\n",
    "    newurons -> list [200,10] nro de neuronas por capa\n",
    "    '''\n",
    "\n",
    "    W1 = np.random.randn(neurons[0], input_size) * 0.001\n",
    "    b1 = np.zeros((neurons[0],1))\n",
    "\n",
    "    W2 = np.random.randn(neurons[1],neurons[0]) * 0.001\n",
    "    b2 = np.zeros((neurons[1],1))\n",
    "    return {'W1':W1,'b1':b1, 'W2':W2, 'b2':b2}\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def scores(x,parameters,activation_fnc):\n",
    "    \"\"\"\n",
    "    x tiene la forma (#pixeles,num samples)\n",
    "    \"\"\"\n",
    "    z1 = parameters['W1'] @ x + parameters['b1']\n",
    "    a1 = activation_fnc(z1) # devuelve func activation \n",
    "    z2 = parameters['W2'] @ a1 + parameters['b2']\n",
    "    return z2, z1, a1\n",
    "\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    exp_scores = np.exp(x)\n",
    "    sum_exp_scores = np.sum(exp_scores,axis=0)\n",
    "    probs = exp_scores/sum_exp_scores\n",
    "    return probs\n",
    "\n",
    "def x_entropy(scores,y,batch_size=64):\n",
    "    probs = softmax(scores)\n",
    "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
    "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
    "\n",
    "    return probs, cost\n",
    "\n",
    "def backward(probs, x, y, z1, a1 , scores, parameters, batch_size=64):\n",
    "    grads = {}\n",
    "    probs[y.squeeze(), np.arange(batch_size)] -= 1 #y_hat - y\n",
    "    dz2 = probs.copy()\n",
    "\n",
    "    dW2 = dz2 @ a1.T / batch_size\n",
    "    db2 = np.sum(dz2, axis=1, keepdims=True) / batch_size\n",
    "    da1 = parameters['W2'].T @ dz2\n",
    "\n",
    "    dz1 = da1.copy()\n",
    "    dz1[z1 <= 0] = 0\n",
    "\n",
    "    dW1 = dz1 @ x\n",
    "    db1 = np.sum(dz1, axis=1, keepdims=True) / batch_size\n",
    "\n",
    "    assert parameters['W1'].shape == dW1.shape, 'W1 no igual forma'\n",
    "    assert parameters['W2'].shape == dW2.shape, 'W2 no igual forma'\n",
    "    assert parameters['b1'].shape == db1.shape, 'b1 no igual forma'\n",
    "    assert parameters['b2'].shape == db2.shape, 'b2 no igual forma'\n",
    "\n",
    "    grads = {'w1':dW1, 'b1': db1, 'w2': dW2, 'b2':db2}\n",
    "    return grads\n",
    "\n",
    "\n",
    "\n",
    "def accuracy(x_data,y_data,mb_size=64):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (x,y) in enumerate(create_minibaches(mb_size,x_data,y_data)):\n",
    "        scores2, z1,a1 = scores(x.T, parameters, relu)\n",
    "        y_hat, cost  = x_entropy(scores2,y , batch_size=len(x))\n",
    "        correct += np.sum(np.argmax(y_hat, axis=0) == y.squeeze())\n",
    "        total += y_hat.shape[1]\n",
    "\n",
    "    return correct/total\n",
    "\n",
    "\n",
    "def train(epochs, parameters, mb_size, learning_rate = 1e-3):\n",
    "    for epoch in range(epochs):\n",
    "        for i , (x,y) in enumerate(create_minibaches(mb_size, x_train, y_train)):\n",
    "            scores2, z1, a1 = scores(x.T, parameters, activation_fnc=relu)\n",
    "            y_hat, cost = x_entropy(scores2,y , batch_size=len(x))\n",
    "            grads = backward(y_hat,x,y,z1,a1,scores2,parameters, batch_size=len(x))\n",
    "\n",
    "            parameters['W1'] = parameters['W1'] - learning_rate*grads['w1']\n",
    "            parameters['b1'] = parameters['b1'] - learning_rate*grads['b1']\n",
    "            parameters['b2'] = parameters['b2'] - learning_rate*grads['b2']\n",
    "            parameters['W2'] = parameters['W2'] - learning_rate*grads['w2']\n",
    "        print(f'cost es: {cost}, y accuray: {accuracy(x_val, y_val, mb_size)}')\n",
    "\n",
    "    return parameters\n",
    "\n",
    "parameters = init_parameters(28*28,[200,10])\n",
    "#scores, z1 , a1 = scores(x_train[:64].T, parameters, relu)\n",
    "#y_hat, cost = x_entropy(scores,y_train[:64])\n",
    "#grads = backward(y_hat, x_train[:64], y_train[:64],z1, a1, scores, parameters)\n",
    "\n",
    "mb_size = 512\n",
    "learning_rate = 1e-2\n",
    "epochs = 20\n",
    "parameters_train = train(epochs=epochs, parameters=parameters, mb_size=mb_size, learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "# print(parameters['W1'].shape)\n",
    "# print(parameters['b1'].shape)\n",
    "# print(parameters['W2'].shape)\n",
    "# print(parameters['b2'].shape)\n",
    "\n",
    "\n",
    "# rnd_idx = np.random.randint(len(y_test))\n",
    "# print(f'La imagen mostrada representa un: {y_test[rnd_idx]})')\n",
    "# plot_number(x_test_num[rnd_idx])\n",
    "\n",
    "\n",
    "# print(x_train.shape) #shape (50000,784)\n",
    "# print(y_train.shape) #shape (50000,1)\n",
    "\n",
    "# print(x_val.shape) #shape(10000,784)\n",
    "# print(y_val.shape) #shape(10000,1)\n",
    "\n",
    "# print(x_test.shape) #shape(10000,784)\n",
    "# print(y_test.shape) #shape(10000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0993946f-3697-40da-ab59-a91a07e5ea1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97098"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x_train,y_train, mb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5ab1b54-10bf-4779-9b7d-8c569e107663",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43maccuracy\u001b[49m(x_test,y_test, mb_size)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy(x_test,y_test, mb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7de5ac87-021e-4437-ac42-7e9af2793976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    scores2, _, _ = scores(x,parameters,relu)\n",
    "    return np.argmax(scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6148adef-e1d5-4814-b70c-c4c607f1f48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAHI0lEQVR4nO3cQXLqRhRAUZRiX7ZWBqwMWJkySOVWBsn/ogMSps4Zq0uvMPatHvhNy7IsBwA4HA5/7D0AAO9DFACIKAAQUQAgogBARAGAiAIAEQUAclz74DRNr5wDgBdb87/KbgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgDkuPcA8DvX6/XhM9/f388fZGe32+3hM/M8P38QPpqbAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAyLQsy7LqwWl69Sx8uNEldSML8fiLJXr805o/924KAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgx70H4GcaWW53Op2ePwi/NPJzOp/Pm5zhPbkpABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAsSWVISPbN0fOvLvL5bLZu7baMvv19bXJe3hPbgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACDTsizLqgen6dWz8INcr9eHz7z7Qrx5nh8+c7vdHj4z+jmMfOZbGVkMeD6fnz8Iv7Tmz72bAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAyHHvAdjfyGKyd19uN2Jkud2W7xlZOnc6nYbe9aivr69N3sPruSkAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYBMy7Isqx6cplfPwk6u1+vDZ959Id48zw+f2Woh3pZW/nrvwt+U7a35PrgpABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAsSWVt96keTiMbS8d2ZL6id55A+7oz+gTt9luxZZUAB4iCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAkOPeA8DvWG437n6/P3xmq4V4o++xEO+13BQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEAsxIMPdj6fHz5zOp2ePwg/hpsCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIhXgfZmQBGsDf3BQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEAsxIMP9v39vfcI/+l2u+09Av/CTQGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgtqfDBTqfT3iP8J1tS35ObAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAyLQsy7LqwWl69SzsZOVXYDe+e+O2+tmOLLeb5/n5g/BLa74PbgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACDHvQeA3/n+/n74zMiCtnc38jls5X6/7z0CT+KmAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAMi3Lsqx6cJpePQs7WfkV2M3Icrt5np8/yM6u1+vDZ7ZaJviJn/cnWvO77qYAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQBy3HsA9jeyAG1k0dqokXedz+dNzowYfc9Wn/n9ft/kPbwnNwUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACDTsizLqgen6dWz8INcr9eHz2y5WXXE5XLZ5D2n02mT9xwOYxtw53l+/iC8hTV/7t0UAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBALMRjyMhyu5Elevw/fm/5JwvxAHiIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQI57D8DPdLvdHj4zupxt5c7GH2PkszscDofL5fLcQeBfuCkAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYBYiMfbG12kBzzOTQGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACDHtQ8uy/LKOQB4A24KAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgDkT2Uu1PyZIuywAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valor predicho es: 0\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(y_test))\n",
    "plot_number(x_test_num[idx])\n",
    "pred = predict(x_test[idx].reshape(-1,1))\n",
    "print(f'valor predicho es: {pred}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
