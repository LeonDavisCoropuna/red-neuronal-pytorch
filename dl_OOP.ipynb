{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "from minst_read import MnistDataloader\n",
    "input_path = './'\n",
    "training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
    "test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n",
    "\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_train_num, y_train_num), (x_test_num, y_test_num) = mnist_dataloader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_num[:50000].reshape(50000,-1).astype(np.float32)\n",
    "y_train = y_train_num[:50000].reshape(50000,1)\n",
    "\n",
    "x_val = x_train_num[50000:].reshape(10000,-1).astype(np.float32)\n",
    "y_val = y_train_num[50000:].reshape(10000,1)\n",
    "\n",
    "x_test = x_test_num.copy().reshape(10000,-1).astype(np.float32)\n",
    "y_test = y_test_num.copy().reshape(10000,1)\n",
    "\n",
    "def plot_number(image):\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33.395157, 78.66619, 0.0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std(), x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x_mean, x_std, x_data):\n",
    "    return (x_data - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train = normalize(x_mean, x_std, x_train)\n",
    "x_val = normalize(x_mean, x_std, x_val)\n",
    "x_test = normalize(x_mean, x_std, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.1638146e-07, 0.99999934, -0.42451727)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std(), x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor es: [7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(len(y_test))\n",
    "print(f'El valor es: {y_test[idx]}')\n",
    "plot_number(x_test_num[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    assert x.shape[0] == y.shape[0], 'Diferente tama√±o'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle:\n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase linear, ReLU y Squential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class np_tensor(np.ndarray): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        '''\n",
    "        Init parameters utilizando Kaiming He\n",
    "        '''\n",
    "        self.W = (np.random.randn(output_size, input_size) / np.sqrt(input_size/2)).view(np_tensor)\n",
    "        self.b = (np.zeros((output_size, 1))).view(np_tensor)\n",
    "    def __call__(self, X): # esta el foward de la clase lineal\n",
    "        Z = self.W @ X + self.b\n",
    "        return Z\n",
    "    def backward(self, X, Z):\n",
    "        X.grad = self.W.T @ Z.grad\n",
    "        self.W.grad = Z.grad @ X.T\n",
    "        self.b.grad = np.sum(Z.grad, axis = 1, keepdims=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __call__(self, Z):\n",
    "        return np.maximum(0, Z)\n",
    "    def backward(self, Z, A):\n",
    "        Z.grad = A.grad.copy()\n",
    "        Z.grad[Z <= 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential_layers():\n",
    "    def __init__(self, layers):\n",
    "        '''\n",
    "        layers - lista que contiene objetos de tipo Linear, ReLU\n",
    "        '''\n",
    "        self.layers = layers\n",
    "        self.x = None\n",
    "        self.outputs = {}\n",
    "    def __call__(self, X):\n",
    "        self.x = X \n",
    "        self.outputs['l0'] = self.x\n",
    "        for i, layer in enumerate(self.layers, 1):\n",
    "            self.x = layer(self.x)\n",
    "            self.outputs['l'+str(i)]=self.x\n",
    "        return self.x\n",
    "    def backward(self):\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            self.layers[i].backward(self.outputs['l'+str(i)], self.outputs['l'+str(i+1)])\n",
    "    def update(self, learning_rate = 1e-3):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, ReLU): continue\n",
    "            layer.W = layer.W - learning_rate * layer.W.grad\n",
    "            layer.b = layer.b - learning_rate * layer.b.grad\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.__call__(X))   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmaxXEntropy(x, y):\n",
    "    batch_size = x.shape[1]\n",
    "    exp_scores = np.exp(x)\n",
    "    probs = exp_scores / exp_scores.sum(axis = 0)\n",
    "    preds = probs.copy()\n",
    "    # Costo\n",
    "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
    "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
    "    # Calcular gradientes\n",
    "    probs[y.squeeze(), np.arange(batch_size)] -= 1 #dl/dx\n",
    "    x.grad = probs.copy()\n",
    "    \n",
    "    return preds, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loops de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, epochs, mb_size=128, learning_rate = 1e-3):\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
    "            scores = model(x.T.view(np_tensor))\n",
    "            _, cost = softmaxXEntropy(scores, y)\n",
    "            model.backward()\n",
    "            model.update(learning_rate)\n",
    "        print(f'costo: {cost}, accuracy: {accuracy(x_val, y_val, mb_size)}')\n",
    "        \n",
    "def accuracy(x, y, mb_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (x, y) in enumerate(create_minibatches(mb_size, x, y)):\n",
    "        pred = model(x.T.view(np_tensor))\n",
    "        correct += np.sum(np.argmax(pred, axis=0) == y.squeeze())\n",
    "        total += pred.shape[1]\n",
    "    return correct/total\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential_layers([Linear(784, 200), ReLU(), Linear(200, 200), ReLU(), Linear(200, 10)])\n",
    "mb_size = 512\n",
    "learning_rate = 1e-4\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_minibatches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmb_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[61], line 3\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, epochs, mb_size, learning_rate)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, epochs, mb_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-3\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m----> 3\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mcreate_minibatches\u001b[49m(mb_size, x_train, y_train)):\n\u001b[0;32m      4\u001b[0m             scores \u001b[38;5;241m=\u001b[39m model(x\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mview(np_tensor))\n\u001b[0;32m      5\u001b[0m             _, cost \u001b[38;5;241m=\u001b[39m softmaxXEntropy(scores, y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_minibatches' is not defined"
     ]
    }
   ],
   "source": [
    "train(model, epochs, mb_size, learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
